input { 
    elasticsearch { 
        hosts => [""*.*.*.*:9200"] 
        index => "logstash-2018.03.27" 
        codec => "json_lines"
        docinfo => true
    } 
} 
filter {
  mutate {
      lowercase => [ "channelType", "log_type" ]
       update => ["message", "%{sourceId} %{callAdvTime} %{orderId} %{orderInputId} %{channelType} %{source} %{userid} %{uuid} %{from_ip} %{delMode} %{log_type} %{repeatTime} %{client_ip} %{scid} %{responseMsg} %{orderSourceId} %{channelTime} %{advId} %{ideaId} %{port} %{appid} %{proId} %{status} %{cid} %{delPlat} %{landingPageId} %{clickTime} %{sc_name} %{channelMoney} %{inputMoney} %{notifyChannelUrl} %{callAdvUrl} %{callChannelUrl}"]
      gsub =>["message","%{[A-Za-z_]*}", 'null']
      lowercase => [ "message" ]
      remove_field => ["level", "source","userid","tags","sc_name","log_type","port","thread_name","level_value","appid","@version","host","client_ip","logger_name","cid","status"]
      add_field => { "type" => "joyplusestohdfs" } 
   }
}
output {
        if "_grokparsefailure" in [tags] {
        stdout {
          codec => rubydebug
         }
       }
 if "_grokparsefailure" not in [tags] {
  if [type] == "joyplusestohdfs" {
    file{ path => "/backup/%{+YYYY-MM-dd}/logstash-%{+YYYY-MM-dd}.log"}
   webhdfs {
     host => "192.168.1.83"
     port => 50070
     path => "/online_backup/%{+YYYY-MM-dd}/logstash-%{+YYYY-MM-dd}.log"
     user => "hadoop"
     compression => "snappy"
     snappy_format => "stream"
    }
  }
 }
}
