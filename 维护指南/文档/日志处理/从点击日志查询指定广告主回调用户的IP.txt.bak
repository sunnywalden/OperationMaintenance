#需求：
##12.27-1.2
##qq飞车   广告主确认日志中idfa对应的clientip   source    sc_name
            
            
            
            
#查询得到回调数据用户的信息 
elasticdump \
  --input=http://106.14.240.250:9200/logstash-* \
  --output=query0123_ack.json \
  --searchBody '{"_source": ["appid","userid","@timestamp","source","cid","sc_name","status"], "query":{"query_string":{"query": "(appid:1235504705 and appid:12355047051) AND (log_type:advAckAllNumber) AND (status:0) AND (@timestamp:[2017-12-27T00:00:00.000Z TO 2018-01-03T00:00:00.000Z])"}},"aggs": {"group_by_cid": {"terms": {"field": "cid.keyword"}}}}'
  
 

 
 ##  格式处理
#过滤得到有效数据
cat query0123_ack.json |while read line;do rec=${line}; echo $rec | jj _source;done > 0123advserack.log 

#增加换行
sed -i 's/}/}\n/g' 0123advserack.log

#转换为csv
sed -i 's/{"sc_name":"//g' 0123advserack.log
sed -i 's/@timestamp":"//g' 0123advserack.log 
sed -i 's/appid"://g' 0123advserack.log 
sed -i 's/source"://g' 0123advserack.log
sed -i 's/userid"://g' 0123advserack.log
sed -i 's/cid"://g' 0123advserack.log
sed -i 's/,"status":0}//g' 0123advserack.log 
sed -i 's/","/,/g' 0123advserack.log

mv 0123advserack.log 0123advserack.csv 

sed -i 's/,"/,/g' 0123advserack.csv 
sed -i 's/"//g' 0123advserack.csv 

sort -k2n 0123advserack.csv| uniq > 0123_advserack.csv

##文件切割，进行多进程处理





## shell script
#多进程方案（将0123_advserack.csv查分为110个文件）
for((i=1;i<=110;i++));do let m=(${i}-1)*1000+1;let n=${i}*1000;sed -n "${m}, ${n}p" 0123_advserack.csvbak > 0123_advserack${i}.csv;done
wc -l 0123_advserack*.csv


#!/bin/bash

for ((sw=1; sw<=110; sw++))
do
  {
  cat walden/0123_advserack${sw}.csv|while read line
  do
    record=${line}
    appid=`echo $record|awk -F ',' '{print $3}'`
    ifa=`echo $record|awk -F ',' '{print $5}'`
    source=`echo $record|awk -F ',' '{print $4}'`
    cid=`echo $record|awk -F ',' '{print $6}'`

    curl -s -g -XGET "http://139.196.106.190:9200/logstash-*/logs/_search?q=(userid:${ifa})AND(appid:${appid})AND(source:${source})AND(cid:${cid})AND(log_type:clickNumber)AND(@timestamp:[2017-12-27T00:00:00.000Z%20TO%202018-01-03T00:00:00.000Z])AND(status:0)&_source=appid,userid,client_ip,source,cid,sc_name" > /tmp/test${sw}
    n=`grep -o "_source" /tmp/test${sw} | wc -l` && let m=$n && for((i=0; i<${m}; i++));do sudo cat /tmp/test${sw}|jj hits.hits.${i}._source >> /tmp/middle${sw}.log;done
  done
  }&
done
wait


echo 'We done here'
echo '------------------------------------------------------------------------------------'

  
 ##  格式处理


#增加换行
sed -i 's/}/}\n/g' /tmp/middle.log

#转换为csv
sed -i 's/{"sc_name":"//g' /tmp/middle.log
 
sed -i 's/appid"://g' /tmp/middle.log 
sed -i 's/client_ip":"//g' /tmp/middle.log
sed -i 's/source"://g' /tmp/middle.log
sed -i 's/userid"://g' /tmp/middle.log
sed -i 's/cid"://g' /tmp/middle.log 
sed -i 's/","/,/g' /tmp/middle.log

mv /tmp/middle.log /tmp/middle.csv 

sed -i 's/,"/,/g' /tmp/middle.csv 
sed -i 's/"}//g' /tmp/middle.csv
sed -i 's/"//g' /tmp/middle.csv


#去重
sort -k2n /tmp/middle.csv| uniq > /tmp/final_0123.csv


vim final.csv
:set fileencoding=gbk

#统计总记录
 wc -l /tmp/final_0123.csv
   
   
   
  
#文件汇总
for((i=1;i<=38;i++));do cat middle${i}.log >> middle_hadoop1.log;done 
ls middle*|sort


 for((i=1;i<=3;i++));do cat middle_hadoop${i}.log >> middle.log;done
 ls -la middle.log 
 grep -o "sc_name" middle.log |wc -l
 cp middle.log middle.logbak
 sed -i 's/}/}\n/g' /tmp/middle.log
 vim middle.log
 sed -i 's/{"sc_name":"//g' /tmp/middle.log
  
 sed -i 's/appid"://g' /tmp/middle.log 
 sed -i 's/client_ip":"//g' /tmp/middle.log
 sed -i 's/source"://g' /tmp/middle.log
 sed -i 's/userid"://g' /tmp/middle.log
 sed -i 's/cid"://g' /tmp/middle.log 
 sed -i 's/","/,/g' /tmp/middle.log
 mv /tmp/middle.log /tmp/middle.csv 
 vim /tmp/middle.csv 
 sed -i 's/,"/,/g' /tmp/middle.csv 
 sed -i 's/"}//g' /tmp/middle.csv
 sed -i 's/"//g' /tmp/middle.csv

#编码转换 Unix to Dos
 vim /tmp/middle.csv
 :set fileencoding=gbk
  
 sort -k2n /tmp/middle.csv| uniq > /tmp/final_0129.csv
 wc -l middle.csv 